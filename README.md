# Snap! Rubric Generator

An AI-powered rubric generation system for Snap! programming assignments using Angular 18 frontend and Node.js backend with RAG (Retrieval-Augmented Generation).

## Documentation

- Stakeholder overview of the database plan: docs/db-plan.md

## Project Structure

```
snapclass-rubrics-generator/
â”œâ”€â”€ client/                 # Angular 18 frontend (Production-ready)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ core/           # Core functionality (interceptors, guards)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ interceptors/
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ error.interceptor.ts
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ logging.interceptor.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ shared/         # Shared resources (models, components)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ rubric.model.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ services/       # API services
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ rubric-api.service.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ pages/          # Feature pages/components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ home/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ rubric-display/
â”‚   â”‚   â”‚   â”œâ”€â”€ app.component.*
â”‚   â”‚   â”‚   â”œâ”€â”€ app.config.ts
â”‚   â”‚   â”‚   â””â”€â”€ app.routes.ts
â”‚   â”‚   â”œâ”€â”€ environments/       # Environment configurations
â”‚   â”‚   â”‚   â”œâ”€â”€ environment.ts
â”‚   â”‚   â”‚   â””â”€â”€ environment.development.ts
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ angular.json
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ server/                 # Node.js backend (Production-ready)
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ config/            # Configuration files
    â”‚   â”‚   â”œâ”€â”€ env.config.js
    â”‚   â”‚   â””â”€â”€ cors.config.js
    â”‚   â”œâ”€â”€ controllers/       # Request handlers
    â”‚   â”‚   â””â”€â”€ rubric.controller.js
    â”‚   â”œâ”€â”€ services/          # Business logic
    â”‚   â”‚   â”œâ”€â”€ ai.service.js
    â”‚   â”‚   â”œâ”€â”€ rag.service.js
    â”‚   â”‚   â”œâ”€â”€ prompt.service.js
    â”‚   â”‚   â””â”€â”€ rubric.service.js
    â”‚   â”œâ”€â”€ routes/            # API routes
    â”‚   â”‚   â”œâ”€â”€ index.js
    â”‚   â”‚   â””â”€â”€ rubric.routes.js
    â”‚   â”œâ”€â”€ middleware/        # Express middleware
    â”‚   â”‚   â”œâ”€â”€ error.middleware.js
    â”‚   â”‚   â””â”€â”€ logger.middleware.js
    â”‚   â”œâ”€â”€ app.js             # Express app configuration
    â”‚   â””â”€â”€ server.js          # Server entry point
    â”œâ”€â”€ data/                  # Data files
    â”‚   â””â”€â”€ all_assignments.json
    â”œâ”€â”€ .env.example           # Environment template
    â”œâ”€â”€ SnapManual.pdf         # RAG document (not in git)
    â””â”€â”€ package.json
```

## Features

- **AI-Powered Generation**: Uses Llama 3.1 70B via Hugging Face for intelligent rubric creation
- **RAG Pipeline**: Retrieves relevant context from Snap! programming manual using vector search
- **Row-Level Regeneration**: Regenerate entire category objectives while preserving point scales
- **Interactive Editing**: Double-click cells to edit, with inline controls
- **Tier-Aware AI**: Understands scoring tiers and maintains consistency across objectives
- **Responsive UI**: Clean, modern interface with expandable instruction panels
- **Production-Ready Architecture**: Proper separation of concerns with MVC pattern
- **Error Handling**: Global error middleware with detailed logging
- **Environment Configuration**: Separate configs for development and production

## Prerequisites

- Node.js 18+ and npm
- Angular CLI 18
- Hugging Face API token (for Llama 3.1 70B access)
- Ollama (for local embeddings)

## Setup

### Backend Setup

1. Navigate to server directory:
   ```bash
   cd server
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. **Add the Snap! Manual PDF**:
   - Download or copy `SnapManual.pdf` to the `server/` directory
   - This file is required for the RAG pipeline but not included in git (it's large)

4. Create `.env` file from template:
   ```bash
   cp .env.example .env
   ```

5. Edit `.env` and add your Hugging Face token:
   ```env
   HF_TOKEN=your_hugging_face_token_here
   PORT=3001
   NODE_ENV=development
   ```

6. Start the server:
   ```bash
   # Development mode (with auto-reload)
   npm run dev
   
   # Production mode
   npm start
   ```
   Server runs on `http://localhost:3001`

### Frontend Setup

1. Navigate to client directory:
   ```bash
   cd client
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Start development server:
   ```bash
   npm start
   # or
   ng serve
   ```
   Frontend runs on `http://localhost:4200`

4. Build for production:
   ```bash
   npm run build
   # Output: dist/client-angular/
   ```

## Usage

1. **Generate Rubric**:
   - Open `http://localhost:4200`
   - Enter assignment title, description, and optional requirements
   - Click "Generate Rubric"

2. **Edit Objectives**:
   - Double-click any cell to edit text and points
   - Click the âœŽ icon in the cell's bottom-right to edit
   - Save changes with the checkmark button

3. **Regenerate Row**:
   - Click the ðŸ”„ button in any category (bottom-right corner)
   - Enter optional instruction for AI guidance
   - Click "Generate" to regenerate all objectives in that row
   - Category and point values remain unchanged

4. **Regenerate Entire Rubric**:
   - Click "Edit & Regenerate All" at the top
   - Modify assignment details if needed
   - Click "Regenerate Entire Rubric"

## Technology Stack

### Frontend
- **Angular 18** - Standalone components architecture
- **TypeScript** - Type-safe development
- **RxJS** - Reactive data handling
- **HTTP Interceptors** - Error handling and logging
- **Environment-based Configuration** - Dev/Prod separation

### Backend
- **Node.js + Express** - REST API server with MVC architecture
- **LangChain** - RAG pipeline orchestration
- **Hugging Face Inference** - Llama 3.1 70B Instruct
- **Ollama Embeddings** - Local vector embeddings
- **MemoryVectorStore** - In-memory vector search (904 chunks)
- **PDFLoader** - Snap! manual ingestion
- **Layered Architecture** - Controllers â†’ Services â†’ Models

## API Endpoints

### Base URL: `/api`

- **Health Check**
  - `GET /api/health` - Server health status

- **Rubric Generation**
  - `POST /api/rubric/generate` - Generate complete rubric
    ```json
    {
      "title": "Assignment Title",
      "description": "Assignment description",
      "question": "Optional requirements"
    }
    ```

- **Rubric Regeneration**
  - `POST /api/rubric/regenerate-row` - Regenerate entire category
    ```json
    {
      "title": "Assignment Title",
      "description": "Assignment description",
      "categoryName": "Category Name",
      "categoryReasoning": "Category purpose",
      "objectives": [...],
      "instruction": "Optional AI guidance"
    }
    ```

  - `POST /api/rubric/regenerate-cell` - Regenerate single objective
    ```json
    {
      "title": "Assignment Title",
      "description": "Assignment description",
      "categoryName": "Category Name",
      "categoryReasoning": "Category purpose",
      "allObjectives": [...],
      "existingObjective": {...},
      "instruction": "Optional AI guidance"
    }
    ```

## Environment Variables

### Server Configuration (`.env`)

```env
# Required
HF_TOKEN=your_hugging_face_token_here

# Optional (with defaults)
PORT=3001
NODE_ENV=development
CORS_ORIGIN=*

# AI Model Configuration
AI_MODEL=meta-llama/Llama-3.1-70B-Instruct
MAX_TOKENS=2048
TEMPERATURE=0.7

# RAG Configuration
DOC_PATH=SnapManual.pdf
CHUNK_SIZE=500
CHUNK_OVERLAP=50
SEARCH_RESULTS=5
```

### Client Configuration

Edit `src/environments/environment.ts` for production:
```typescript
export const environment = {
  production: true,
  apiUrl: '/api', // Relative URL for production
  apiTimeout: 60000,
};
```

Edit `src/environments/environment.development.ts` for development:
```typescript
export const environment = {
  production: false,
  apiUrl: 'http://localhost:3001/api',
  apiTimeout: 60000,
};
```

## Deployment

### Backend Deployment

1. Set environment variables on your server
2. Install dependencies: `npm install --production`
3. Start server: `npm start`
4. Ensure `SnapManual.pdf` is in the server directory

### Frontend Deployment

1. Build for production: `npm run build`
2. Deploy `dist/client-angular/` folder to your web server
3. Configure server to serve `index.html` for all routes (SPA routing)
4. Update `environment.ts` with production API URL

### Docker Deployment (Future Enhancement)

Consider containerizing both frontend and backend for easier deployment.

## Development Notes

- Backend initializes vector store at startup (904 chunks from Snap! manual)
- Point values are preserved during regeneration to maintain table alignment
- Objectives sorted descending by points (highest quality â†’ lowest)
- HTTP interceptors provide automatic error handling and request/response logging
- Modular service architecture allows easy testing and maintenance

## Ports

- Frontend: `4200` (development)
- Backend: `3001` (configurable via .env)

## Scripts

### Server
- `npm start` - Start production server
- `npm run dev` - Start development server with auto-reload

### Client
- `npm start` - Start development server
- `npm run build` - Build for production
- `npm test` - Run unit tests
- `ng serve` - Alternative to start dev server
- `ng build --configuration production` - Production build

## Architecture Highlights

### Backend (MVC Pattern)
- **Controllers**: Handle HTTP requests/responses
- **Services**: Business logic and orchestration
- **Config**: Centralized configuration management
- **Middleware**: Cross-cutting concerns (logging, errors)
- **Routes**: API endpoint definitions

### Frontend (Angular Best Practices)
- **Core Module**: Singleton services and app-wide functionality
- **Shared Module**: Reusable components and models
- **Feature Modules**: Lazy-loaded page components
- **Interceptors**: HTTP request/response transformation
- **Environment Files**: Configuration per environment

## License

MIT

## Contributors

[Your Name/Team]

